# AlgoRhythm 📻

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/charliermarsh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![security: bandit](https://img.shields.io/badge/security-bandit-yellow.svg)](https://github.com/PyCQA/bandit)
[![Checked with mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](https://mypy-lang.org/)

## 🎯 Description

# 🎵 AlgoRhythm

**AlgoRhythm** is a music and album recommendation system based on the musical preferences of real or synthetic users. It uses Spotify's public API to extract real-time data and generate personalized suggestions. Developed as the final project for the **Data Science in Production** course.

## 🚀 What does this project do?

-   Builds user music profiles based on:
    -   Favorite songs and albums (real from Spotify or simulated via surveys/synthetic data)
    -   Ratings or popularity scores
-   Extracts dynamic data from Spotify using its API:
    -   Information about tracks, albums, and artists
    -   Popular playlists such as the global or genre-specific Top 50
-   Applies a content-based recommendation system:
    -   Compares musical attributes (genre, popularity, artists) between favorite songs and songs in the charts
    -   Uses clustering and similarity to suggest new music
    -   Filters out songs the user already listens to
-   Delivers personalized recommendations per user
-   Includes visualizations to interpret musical profiles and recommendations

The solution is built using a professional data engineering approach, covering the entire pipeline: from data acquisition and processing to training, evaluating, and deploying recommendation models.

## ✨ Features and Tools

Tools used in this project:

| Feature                         | Tool                     | Justification                           |
| ------------------------------- | ------------------------ | --------------------------------------- |
| Dependency management           | [UV]                     | Fast and reproducible environments      |
| Configuration management        | [Hydra]                  | Flexible parameter handling             |
| Code quality (linting, imports) | [Ruff]                   | Clean and consistent code               |
| Static type checking            | [Mypy]                   | Robustness and early error detection    |
| Code security                   | [Bandit]                 | Vulnerability detection                 |
| Pre-commit validations          | [Pre-commit]             | Maintain code quality standards         |
| Unit testing                    | [Pytest]                 | System behavior validation              |
| Test coverage tracking          | [coverage.py] [Codecov]  | Monitor test completeness               |
| Project templating              | [Cruft] / [Cookiecutter] | Professional data science template      |
| Professional data structure     | [Data structure]         | Clear and scalable project organization |

## 🚀 Environment Setup

1. Initialize the Git repository:

    ```bash
    make init_git
    ```

1. Set up the environment:

    ```bash
    make init_env
    ```

1. Install libraries for data science and machine learning:

    ```bash
    make install_data_libs
    ```

## Install dependencies

After init the environment to install a new package, run:

```bash
uv add <package-name>
```

Example to install [plotly](https://plotly.com/python/) in dev group:

```bash
uv add --group dev plotly
```

## 🗃️ Project structure

-   [Data structure]
-   [Pipelines based on Feature/Training/Inference Pipelines](https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines)

```bash
.
├── codecov.yml                         # configuration for codecov
├── .code_quality
│   ├── mypy.ini                        # mypy configuration
│   └── ruff.toml                       # ruff configuration
├── data
│   ├── 01_raw                          # raw immutable data
│   ├── 02_intermediate                 # typed data
│   ├── 03_primary                      # domain model data
│   ├── 04_feature                      # model features
│   ├── 05_model_input                  # often called 'master tables'
│   ├── 06_models                       # serialized models
│   ├── 07_model_output                 # data generated by model runs
│   ├── 08_reporting                    # reports, results, etc
│   └── README.md                       # description of the data structure
├── docs                                # documentation for your project
├── .editorconfig                       # editor configuration
├── .github                             # github configuration
│   ├── dependabot.md                   # github action to update dependencies
│   ├── pull_request_template.md        # template for pull requests
│   └── workflows                       # github actions workflows
│       ├── ci.yml                      # run continuous integration (tests, pre-commit, etc.)
│       ├── dependency_review.yml       # review dependencies
│       ├── docs.yml                    # build documentation (mkdocs)
│       └── pre-commit_autoupdate.yml   # update pre-commit hooks
├── .gitignore                          # files to ignore in git
├── Makefile                            # useful commands to setup environment, run tests, etc.
├── models                              # store final models
├── notebooks
│   ├── 1-data                          # data extraction and cleaning
│   ├── 2-exploration                   # exploratory data analysis (EDA)
│   ├── 3-analysis                      # Statistical analysis, hypothesis testing.
│   ├── 4-feat_eng                      # feature engineering (creation, selection, and transformation.)
│   ├── 5-models                        # model training, evaluation, and hyperparameter tuning.
│   ├── 6-interpretation                # model interpretation
│   ├── 7-deploy                        # model packaging, deployment strategies.
│   ├── 8-reports                       # story telling, summaries and analysis conclusions.
│   ├── notebook_template.ipynb         # template for notebooks
│   └── README.md                       # information about the notebooks
├── .pre-commit-config.yaml             # configuration for pre-commit hooks
├── pyproject.toml                      # dependencies for the python project
├── README.md                           # description of your project
├── src                                 # source code for use in this project
│   ├── README.md                       # description of src structure
│   ├── tmp_mock.py                     # example python file
│   ├── data                            # data extraction, validation, processing, transformation
│   ├── model                           # model training, evaluation, validation, export
│   ├── inference                       # model prediction, serving, monitoring
│   └── pipelines                       # orchestration of pipelines
│       ├── feature_pipeline            # transforms raw data into features and labels
│       ├── training_pipeline           # transforms features and labels into a model
│       └── inference_pipeline          # takes features and a trained model for predictions
├── tests                               # test code for your project
│   ├── test_mock.py                    # example test file
│   ├── data                            # tests for data module
│   ├── model                           # tests for model module
│   ├── inference                       # tests for inference module
│   └── pipelines                       # tests for pipelines module
└── .vscode                             # vscode configuration
    ├── extensions.json                 # list of recommended extensions
    ├── launch.json                     # vscode launch configuration
    └── settings.json                   # vscode settings
```

## 👥 Authors

-   Simón Correa Marín
-   Luis Felipe Ospina Giraldo

## Credits

This project was generated from [@JoseRZapata]'s [data science project template] template.

---

[@JoseRZapata]: https://github.com/JoseRZapata
[bandit]: https://github.com/PyCQA/bandit
[codecov]: https://codecov.io/
[Cookiecutter]: https://cookiecutter.readthedocs.io/en/stable/
[coverage.py]: https://coverage.readthedocs.io/
[Cruft]: https://cruft.github.io/cruft/
[data science project template]: https://github.com/JoseRZapata/data-science-project-template
[Data structure]: https://github.com/JoseRZapata/data-science-project-template/blob/main/music-recommendation-system/data/README.md
[hydra]: https://hydra.cc/
[Mypy]: http://mypy-lang.org/
[pre-commit]: https://pre-commit.com/
[Pytest]: https://docs.pytest.org/en/latest/
[Ruff]: https://docs.astral.sh/ruff/
[UV]: https://docs.astral.sh/uv/
